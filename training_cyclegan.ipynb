{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORT LIBRARIES\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image, make_grid\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OPTIONS\n",
    "choices = ['ae_photos', 'apple2orange', 'cezanne2photo','cityscapes',\n",
    "          'facades', 'horse2zebra', 'iphone2dslr_flower', 'maps',\n",
    "          'monet2photo', 'summer2winter_yosemite', 'ukiyoe2photo','vangogh2photo']\n",
    "set_dataset_name = choices[5]  \n",
    "set_dataset_dir = 'cyclegan_data'\n",
    "set_debugs_dir = f'cyclegan_debugs/{set_dataset_name}'\n",
    "set_outimages_dir = f'cyclegan_images/{set_dataset_name}'\n",
    "set_outmodels_dir = f'cyclegan_models/{set_dataset_name}'\n",
    "set_G_AB_file = f'{set_outmodels_dir}/G_AB' \n",
    "set_G_BA_file = f'{set_outmodels_dir}/G_BA' \n",
    "set_D_AB_file = f'{set_outmodels_dir}/D_AB' \n",
    "set_D_BA_file = f'{set_outmodels_dir}/D_BA' \n",
    "set_random_seed = 1\n",
    "set_epoch_start = 0\n",
    "set_epoch_decay = 50\n",
    "set_epoch_end = 100\n",
    "set_batch_size = 2 ##if run out of memory, choose a smaller number for set_batch_size\n",
    "set_lr = 0.0002\n",
    "set_beta1 = 0.5 \n",
    "set_beta2 = 0.999 \n",
    "set_num_cpu = 1\n",
    "set_save_interval = 100 ##if out of storage, choose a larger number for set_save_interval\n",
    "set_lambda_cyc = 10.0\n",
    "set_lambda_id = 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DOWNLOAD DATASET\n",
    "download_file = set_dataset_name + '.zip'\n",
    "url = 'https://people.eecs.berkeley.edu/~taesung_park/CycleGAN/datasets/' + download_file\n",
    "!mkdir -p $set_dataset_dir\n",
    "%cd $set_dataset_dir\n",
    "!wget -N $url\n",
    "!unzip -o $download_file \n",
    "%cd -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATASET\n",
    "##define custom dataset\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, root, train=True, transforms=None):\n",
    "        self.train = train\n",
    "        if train:\n",
    "            path_A, dirs_A, file_names_A = next(os.walk(root + '/trainA/'))\n",
    "            path_B, dirs_B, file_names_B = next(os.walk(root + '/trainB/'))\n",
    "        else:\n",
    "            path_A, dirs_A, file_names_A  = next(os.walk(root + '/testA/'))\n",
    "            path_B, dirs_B, file_names_B = next(os.walk(root + '/testB/'))\n",
    "        self.abs_paths_A = [path_A + name for name in file_names_A]\n",
    "        self.abs_paths_B = [path_B + name for name in file_names_B]\n",
    "        ##transform\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def convert_rgb(self, image):\n",
    "        if image.mode != \"RGB\":\n",
    "            image = Image.new(\"RGB\", image.size)\n",
    "            image.paste(image)\n",
    "        return image\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        ###pair (image_A, image_B) \n",
    "        index_A = random.randint(0, len(self.abs_paths_A) - 1)\n",
    "        index_B = random.randint(0, len(self.abs_paths_B) - 1)\n",
    "        image_A = Image.open(self.abs_paths_A[index_A])\n",
    "        image_B = Image.open(self.abs_paths_B[index_B])\n",
    "        ###Convert grayscale images to rgb\n",
    "        image_A = self.convert_rgb(image_A)\n",
    "        image_B = self.convert_rgb(image_B)\n",
    "        ###transform to tensor    \n",
    "        if self.transforms is not None:\n",
    "            image_A = self.transforms(image_A)\n",
    "            image_B = self.transforms(image_B)\n",
    "        return {\"A\": image_A, \"B\": image_B }\n",
    "\n",
    "    def __len__(self):\n",
    "        return max(len(self.abs_paths_A ), len(self.abs_paths_B))\n",
    "\n",
    "\n",
    "##image transformations\n",
    "custom_transform = transforms.Compose(\n",
    "    [transforms.RandomHorizontalFlip(),\n",
    "    transforms.Resize((286,286)),\n",
    "    transforms.RandomCrop((256,256)),\n",
    "    transforms.ToTensor(),###to range [0, 1]\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])])###to range [-1 1]\n",
    "    \n",
    "##create dataloader    \n",
    "train_dataset = CustomDataset(f'{set_dataset_dir}/{set_dataset_name}', True, custom_transform)\n",
    "val_dataset = CustomDataset(f'{set_dataset_dir}/{set_dataset_name}', False, custom_transform)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=set_batch_size, shuffle=True, num_workers=set_num_cpu)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=5, shuffle=True, num_workers=set_num_cpu)\n",
    "save_condition = set_save_interval <= len(train_loader)\n",
    "assert save_condition, f'''\n",
    "The set_save_interval must be less than or equal to total number batches in one epoch of train dataset,\n",
    "so it must lie between [1, {len(train_loader)})\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEFINE BASE MODELS\n",
    "class ConvolutionalBlock(nn.Module):\n",
    "    def __init__(self, kernel_name, in_channels, out_channels, kernel_size, stride, padding, activation_name=None):\n",
    "        super(ConvolutionalBlock, self).__init__()\n",
    "        kernel_layer = getattr(nn, kernel_name)\n",
    "        self.covolutional_block = nn.Sequential(\n",
    "            kernel_layer(in_channels, out_channels, kernel_size, stride, padding, bias=False)\n",
    "        )\n",
    "        if activation_name is not None:\n",
    "            activation = getattr(nn, activation_name) \n",
    "            self.covolutional_block.add_module('activation', activation())\n",
    "                \n",
    "    def forward(self, x):\n",
    "        return self.covolutional_block(x)\n",
    "##--------------------------------------------------------------------------------------------------------------   \n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.residual = nn.Sequential(\n",
    "            ConvolutionalBlock('Conv2d', in_channels, in_channels, 3, 1, 1, 'ReLU'),\n",
    "            ConvolutionalBlock('Conv2d', in_channels, in_channels, 3, 1, 1, 'ReLU'))\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = x ###shortcut path\n",
    "        out = self.residual(x) ###main path\n",
    "        out += shortcut ###gather path\n",
    "        return out\n",
    "##--------------------------------------------------------------------------------------------------------------\n",
    "class MultipleResiduals(nn.Module):\n",
    "    def __init__(self, in_channels, num_repeat):\n",
    "        super(MultipleResiduals, self).__init__()\n",
    "        index = list(range(num_repeat))\n",
    "        self.multiple_residuals = nn.Sequential()\n",
    "        for i in range(num_repeat):\n",
    "            self.multiple_residuals.add_module(f'{index[i]}th_multiple_residuals', ResidualBlock(in_channels))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.multiple_residuals(x)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"static/depict/cyclegan_generator.png\" style=\"width:70%\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        ###generator is similar to autoencoder\n",
    "        self.generator = nn.Sequential(\n",
    "            ###encoder part\n",
    "            ### formular to calculate padding for Conv2d\n",
    "            ### at https://sebastianraschka.com/pdf/lecture-notes/stat479ss19/L13_intro-cnn-part2_slides.pdf\n",
    "                ### (i - k + 2*p)/s + 1 = o round floor\n",
    "                ### => p = (s(o-1) - i + k)/2 ###round up\n",
    "                ### if s=1, o=i then p = (1(i-1) - i + k)/2 = (k-1)/2\n",
    "            ###kernel_name, in_channels, out_channels, kernel_size, stride, padding, activation_name\n",
    "            ConvolutionalBlock('Conv2d', 3, 64, 7, 1, 3, 'ReLU'), ### i\n",
    "            ConvolutionalBlock('Conv2d', 64, 128, 3, 2, 1, 'ReLU'), ### i/2\n",
    "            ConvolutionalBlock('Conv2d', 128, 256, 3, 2, 1, 'ReLU'), ### i/4\n",
    "            \n",
    "            ###transformer part\n",
    "            MultipleResiduals(256, 6), ### i/4\n",
    "            \n",
    "            ###decoder part\n",
    "            ### calculate padding for ConvTranspose2d:\n",
    "                ###o = s(n-1) + k - 2p\n",
    "                ###if s=2 then output = 2(n-1) + k - 2p = 2n - 2 + k -2p\n",
    "            ###kernel_name, in_channels, out_channels, kernel_size, stride, padding, activation_name\n",
    "            ConvolutionalBlock('ConvTranspose2d', 256, 128, 2, 2, 0, 'ReLU'), ### i/2\n",
    "            ConvolutionalBlock('ConvTranspose2d', 128, 64, 2, 2, 0, 'ReLU'), ### i\n",
    "            ConvolutionalBlock('Conv2d', 64, 3, 7, 1, 3, 'Tanh') ### i\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.generator(x) ###output size(set_batch_size, 3, 256, 256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"static/depict/cyclegan_discriminator.png\" style=\"width:70%\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.discriminator = nn.Sequential(\n",
    "            ###kernel_name, in_channels, out_channels, kernel_size, stride, padding, activation_name\n",
    "            ConvolutionalBlock('Conv2d', 3, 64, 4, 2, 1, 'LeakyReLU'), ### i/2\n",
    "            ConvolutionalBlock('Conv2d', 64, 128, 4, 2, 1, 'LeakyReLU'), ### i/4\n",
    "            ConvolutionalBlock('Conv2d', 128, 256, 4, 2, 1, 'LeakyReLU'), ### i/8\n",
    "            ConvolutionalBlock('Conv2d', 256, 512, 4, 2, 1, 'LeakyReLU'), ### i/16\n",
    "            nn.ZeroPad2d((1, 0, 1, 0)),###reference at https://pytorch.org/docs/master/generated/torch.nn.ZeroPad2d.html\n",
    "            ConvolutionalBlock('Conv2d', 512, 1, 4, 1, 1, 'Sigmoid'), ### i/16\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.discriminator(x) ###output size(set_batch_size, 1, 16, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SETUP MODELS\n",
    "## initialize models\n",
    "torch.manual_seed(set_random_seed)\n",
    "G_AB = Generator()\n",
    "G_BA = Generator()\n",
    "D_A = Discriminator()\n",
    "D_B = Discriminator()\n",
    "    \n",
    "\n",
    "##device\n",
    "###one gpu or cpu\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "G_AB = G_AB.to(device)\n",
    "G_BA = G_BA.to(device)\n",
    "D_A = D_A.to(device)\n",
    "D_B = D_B.to(device)\n",
    "parallel=False\n",
    "### multiple gpus\n",
    "if device.type != 'cpu' and torch.cuda.device_count() > 1:\n",
    "    parallel = True\n",
    "    G_AB = nn.DataParallel(G_AB)\n",
    "    G_BA = nn.DataParallel(G_BA)\n",
    "    D_A = nn.DataParallel(D_A)\n",
    "    D_B = nn.DataParallel(D_B)\n",
    "    \n",
    "\n",
    "## load pretrained model weights if you train model in several times\n",
    "if set_epoch_start > 0:  \n",
    "    ###in order to use pretrained model weight, you must rename the last weight G_AB@number1_number2.pt to G_AB.pt \n",
    "    set_G_AB_file = f'{set_outmodels_dir}/G_AB.pt' \n",
    "    ###in order to use pretrained model weight, you must rename the last weight G_BA@number1_number2.pt to G_BA.pt \n",
    "    set_G_BA_file = f'{set_outmodels_dir}/G_BA.pt' \n",
    "    ###in order to use pretrained model weight, you must rename the last weight D_AB@number1_number2.pt to D_AB.pt \n",
    "    set_D_AB_file = f'{set_outmodels_dir}/D_AB.pt' \n",
    "    ###in order to use pretrained model weight, you must rename the last weight D_BA@number1_number2.pt to D_BA.pt \n",
    "    set_D_BA_file = f'{set_outmodels_dir}/D_BA.pt' \n",
    "    \n",
    "    models = [G_AB, G_BA, D_A, D_B]\n",
    "    model_files = [set_G_AB_file, set_G_BA_file, set_D_AB_file, set_D_BA_file]\n",
    "    for f, m in zip(model_files, models):\n",
    "        if parallel:\n",
    "            m.module.load_state_dict(torch.load(f))\n",
    "        else:\n",
    "            m.load_state_dict(torch.load(f))             \n",
    "\n",
    "##optimizers\n",
    "optim_G_AB = torch.optim.Adam(G_AB.parameters(), lr=set_lr, betas=(set_beta1, set_beta2))\n",
    "optim_G_BA = torch.optim.Adam(G_BA.parameters(), lr=set_lr, betas=(set_beta1, set_beta2))\n",
    "optim_D_A = torch.optim.Adam(D_A.parameters(), lr=set_lr, betas=(set_beta1, set_beta2))\n",
    "optim_D_B = torch.optim.Adam(D_B.parameters(), lr=set_lr, betas=(set_beta1, set_beta2))\n",
    "\n",
    "\n",
    "##learing rate scheduler\n",
    "condition_1 = set_epoch_decay > set_epoch_start\n",
    "condition_2 = set_epoch_decay < set_epoch_end\n",
    "assert condition_1 and  condition_2, 'The set_epoch_decay value must lie between (set_epoch_start, set_epoch_end)'\n",
    "lambda_func = lambda epoch: 1 - max(0, epoch + set_epoch_start - set_epoch_decay ) / (set_epoch_end - set_epoch_decay)\n",
    "scheduler_G_AB = LambdaLR(optim_G_AB, lr_lambda=lambda_func)\n",
    "scheduler_G_BA = LambdaLR(optim_G_BA, lr_lambda=lambda_func)\n",
    "scheduler_D_A = LambdaLR(optim_D_A, lr_lambda=lambda_func)\n",
    "scheduler_D_B = LambdaLR(optim_D_B, lr_lambda=lambda_func)\n",
    "\n",
    "##generate cyclegan image from val_loader input\n",
    "def sample_images(image_name):\n",
    "    batch = next(iter(val_loader))\n",
    "    with torch.no_grad():\n",
    "        real_A = batch[\"A\"].to(device)\n",
    "        real_B = batch[\"B\"].to(device)\n",
    "        fake_A = G_BA(real_B)\n",
    "        fake_B = G_AB(real_A)\n",
    "    ### Arange images along x-axis\n",
    "    real_A = make_grid(real_A, nrow=5, normalize=True)\n",
    "    real_B = make_grid(real_B, nrow=5, normalize=True)\n",
    "    fake_A = make_grid(fake_A, nrow=5, normalize=True)\n",
    "    fake_B = make_grid(fake_B, nrow=5, normalize=True)\n",
    "    ### Arange images along y-axis\n",
    "    image = torch.cat((real_A, fake_B, real_B, fake_A), 1)\n",
    "    ###save image\n",
    "    if os.path.exists(set_outimages_dir) == False:\n",
    "        os.makedirs(set_outimages_dir)\n",
    "    set_outimage_file = f'{set_outimages_dir}/{image_name}.png'\n",
    "    save_image(image, set_outimage_file, normalize=False)\n",
    "    return image\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING \n",
    "print('Please wait for training ...', end=\"\")\n",
    "for epoch in range(set_epoch_start, set_epoch_end):\n",
    "    for batch_idx, batch in enumerate(train_loader):\n",
    "        #starting time for every batch\n",
    "        time_start = time.time()\n",
    "        ##Inputs And Ground Truths\n",
    "        real_A = batch[\"A\"].to(device)\n",
    "        real_B = batch[\"B\"].to(device)\n",
    "        p_size = (real_A.size(0), 1, 16, 16) \n",
    "        valid = torch.ones(p_size).float().to(device)\n",
    "        fake = torch.zeros(p_size).float().to(device)\n",
    "        \n",
    "        ##Train Generators\n",
    "        ###start from input A\n",
    "        fake_B = G_AB(real_A)\n",
    "        cycle_A = G_BA(fake_B)\n",
    "        id_A = G_BA(real_A)\n",
    "        ###start from input B\n",
    "        fake_A = G_BA(real_B)\n",
    "        cycle_B = G_AB(fake_A)\n",
    "        id_B = G_AB(real_B)\n",
    "        ###loss gan from input A\n",
    "        loss_gan_AB = F.l1_loss(D_B(fake_B), valid)\n",
    "        loss_cycle_A = F.l1_loss(cycle_A, real_A)\n",
    "        loss_id_A = F.l1_loss(id_A, real_A)\n",
    "        ###loss gan from input B\n",
    "        loss_gan_BA = F.l1_loss(D_A(fake_A), valid)\n",
    "        loss_cycle_B = F.l1_loss(cycle_B, real_B)\n",
    "        loss_id_B = F.l1_loss(id_B, real_B)\n",
    "        ###total loss_generator\n",
    "        loss_gan = 0.5 * (loss_gan_AB + loss_gan_BA)\n",
    "        loss_cycle = 0.5 * (loss_cycle_A + loss_cycle_B)\n",
    "        loss_identity = 0.5 * (loss_id_A + loss_id_B)\n",
    "        loss_G = loss_gan + set_lambda_cyc * loss_cycle + set_lambda_id * loss_identity\n",
    "        ###backward and update gradient\n",
    "        optim_G_AB.zero_grad()\n",
    "        optim_G_BA.zero_grad()\n",
    "        loss_G.backward()\n",
    "        optim_G_AB.step()\n",
    "        optim_G_BA.step()\n",
    "        \n",
    "\n",
    "        ##Train Discriminator\n",
    "        ###loss discriminator from input A\n",
    "        p_real_A = D_A(real_A)\n",
    "        p_fake_A = D_A(fake_A.detach())\n",
    "        loss_real_A = F.mse_loss(p_real_A, valid)\n",
    "        loss_fake_A = F.mse_loss(p_fake_A, fake)\n",
    "        ###loss discriminator from input B\n",
    "        p_real_B = D_B(real_B)\n",
    "        p_fake_B = D_B(fake_B.detach())\n",
    "        loss_real_B = F.mse_loss(p_real_B, valid)\n",
    "        loss_fake_B = F.mse_loss(p_fake_B, fake)\n",
    "        with torch.no_grad():\n",
    "            mp_fake_A = p_fake_A.mean().item()####it is the mean of probabilities in p_fake_A\n",
    "            mp_real_A = p_real_A.mean().item()####it is the mean of probabilities in p_real_A\n",
    "            mp_fake_B = p_fake_B.mean().item()####it is the mean of probabilities in p_fake_B\n",
    "            mp_real_B = p_real_B.mean().item()####it is the mean of probabilities in p_real_B\n",
    "        ##total loss discrimnator\n",
    "        loss_D_A = 0.5 * (loss_real_A + loss_fake_A)\n",
    "        loss_D_B = 0.5 * (loss_real_B + loss_fake_B)\n",
    "        loss_D = 0.5 * (loss_D_A + loss_D_B)\n",
    "        ##backward and update gradient\n",
    "        optim_D_A.zero_grad()\n",
    "        optim_D_B.zero_grad()\n",
    "        loss_D.backward()\n",
    "        optim_D_A.step()\n",
    "        optim_D_B.step()\n",
    "        \n",
    "            \n",
    "        ##for every set_save_interval\n",
    "        if batch_idx % set_save_interval == 0:\n",
    "            ### calulate time remain\n",
    "            if (epoch == set_epoch_start and batch_idx == 0):\n",
    "                print('...')\n",
    "                continue\n",
    "            batches_per_epoch = len(train_loader)\n",
    "            batches_total = (set_epoch_end - set_epoch_start) * batches_per_epoch\n",
    "            batches_complete = (epoch - set_epoch_start) * batches_per_epoch + batch_idx\n",
    "            batches_remain = batches_total - batches_complete\n",
    "            time_remain = datetime.timedelta(seconds=batches_remain * (time.time() - time_start))\n",
    "            time_remain = str(time_remain).split(\".\")[0] ###remove microsecond part\n",
    "            ###log text\n",
    "            print('P(real_A): %.10f' % (mp_real_A))\n",
    "            print('P(fake_A): %.10f' % (mp_fake_A))\n",
    "            print('P(real_B): %.10f' % (mp_real_B))\n",
    "            print('P(fake_B): %.10f' % (mp_fake_B))\n",
    "            print('Epoch:%03d/%03d | Batch:%03d/%03d | D:%.3f | G:%.3f | adv:%.3f | cyc:%.3f | id:%.3f | remain: %s' \n",
    "                   %(epoch+1, set_epoch_end, batch_idx, batches_per_epoch,\n",
    "                   loss_D, loss_G, loss_gan, loss_cycle, loss_identity,\n",
    "                   time_remain))\n",
    "            print('======================================================================================================')\n",
    "            ###save images\n",
    "            image_name = f'{epoch+1}_{batch_idx}'\n",
    "            sample_images(image_name)\n",
    "            ###save models\n",
    "            models = [G_AB, G_BA, D_A, D_B]\n",
    "            files = [set_G_AB_file, set_G_BA_file, set_D_AB_file, set_D_BA_file]\n",
    "            for file, model in zip(files, models):\n",
    "                if not os.path.exists(set_outmodels_dir):\n",
    "                    os.makedirs(set_outmodels_dir)\n",
    "                if parallel:\n",
    "                    torch.save(model.module.state_dict(), file + f'@{epoch+1}_{batch_idx}.pt')##save weight model when running in parallel\n",
    "                else:\n",
    "                    torch.save(model.state_dict(), file + f'@{epoch+1}_{batch_idx}.pt')##save weight model when running without parallel\n",
    "    ##schedule learning rate\n",
    "    scheduler_G_AB.step()\n",
    "    scheduler_G_BA.step()        \n",
    "    scheduler_D_A.step()\n",
    "    scheduler_D_B.step()  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RELEASE GPU(s) MEMORY IF USING GPU(s)\n",
    "del G_AB\n",
    "del G_BA\n",
    "del D_A\n",
    "del D_B\n",
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
